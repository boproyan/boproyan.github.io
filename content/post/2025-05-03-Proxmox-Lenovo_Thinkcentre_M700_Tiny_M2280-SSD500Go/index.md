+++
title = 'Proxmox Lenovo Thinkcentre M700 Tiny'
date = 2025-08-07
categories = ['debian']
+++
*Proxmox VE est une plate-forme open-source compl√®te pour la virtualisation d'entreprise. Gr√¢ce √† l'interface Web int√©gr√©e, vous pouvez facilement g√©rer les machines virtuelles, le stockage, la mise en r√©seau, ...*

![](proxmox-logo.png){: .normal}  

## Proxmox

### Liens


*    Site Officiel de Proxmox VE : <https://www.proxmox.com/proxmox-ve> 
*    Documentation de Proxmox VE : <https://pve.proxmox.com/wiki/>
*    Projet GitHub de Proxmox VE : <https://github.com/proxmox>
* [D√©buter avec Proxmox VE : installation et premiers pas](https://www.it-connect.fr/tuto-bien-debuter-avec-proxmox-ve/)

### Installation via ISO

* Installation sur machine [Lenovo ThinkCentre M700 Tiny](/posts/Description_materiel_Lenovo_ThinkCentre_M700_Tiny_et_mise_a_jour_BIOS/)
* [Comment installer Proxmox VE 8 et cr√©er des VMs ?](https://www.oameri.com/comment-installer-proxmox-ve-8-et-creer-des-vms/)
* Proxmox ISO 
    * Fichier **proxmox-ve_8.4-1.iso** 
    * Version 8.4-1  
    * File Size  1.57 GB  
    * Last Updated  April 09, 2025   
    * SHA256SUM    d237d70ca48a9f6eb47f95fd4fd337722c3f69f8106393844d027d28c26523d8

Installer ISO sur cl√© usb /dev/sdx 

    sudo dd if=proxmox-ve_8.4-1.iso of=/dev/sdx bs=4M

D√©marrer la machine Lenovo sur la cl√© USB et proc√©der √† l'installation de Proxmox

Interface : eno1  
FQDN : pve.home.arpa   
IP address: 192.168.0.215/24  
Gateway: 192.168.0.205  
DNS: 192.168.0.205  

Red√©marage √† la fin de l'installation et acc√®s lien <https://192.168.0.215:8006>

Pour acc√©der √† l'interface, connectez-vous en tant que root et fournissez le mot de passe que vous d√©finissez lors de l'installation de Proxmox.  
![](proxleno01.png){: width="300" .normal}

Une bo√Æte de dialogue appara√Æt en disant qu'il n'y a pas d'abonnement valide pour le serveur. Proxmox offre un service compl√©mentaire optionnel auquel vous pouvez vous abonner. Pour ignorer le message, cliquez sur OK.  
![](proxleno01a.png){: .normal}


### Acc√®s proxleno via SSH

*SSH activ√© avec autorisation connexion root*

Acc√®s SSH : `ssh root@192.168.0.215`

#### Cr√©√© un second compte administrateur sur PROXMOX

Cr√©√© s‚Äôil n‚Äôexiste pas d√©j√† l‚Äôutilisateur **leno** sur votre serveur

    adduser leno

Cette commande permet d‚Äôajouter l‚Äôutilisateur √† la base d‚Äôauthentification proxmox

    pveum useradd leno@pam

Cette commande change le mot de passe de l‚Äôutilisateur attention elle changera aussi le mot de passe du compte associ√© sur votre serveur. Vous pouvez ne pas l‚Äôutiliser si vous avez en t√™te votre mot de passe.

    pveum passwd leno@pam

Cette commande ajoute les droits Administrateurs sur toute l‚Äôinterface √† l‚Äôutilisateur qu‚Äôon vient de cr√©er.

    pveum aclmod / -user leno@pam -roles Administrator

Cette commande d√©sactive le compte administrateur root

    pveum usermod root@pam -enable 0

Si lors d‚Äôune manipulation vous avez un souci √©trange et qu‚Äôil r√©clame le compte root (ajout de certificat par exemple) vous pouvez le r√©activer avec l‚Äôinterface web ou avec la commande.

    pveum usermod root@pam -enable 1

#### Connexion SSH PC1 --> Lenovo

**connexion avec cl√©**  
<u>sur l'ordinateur de bureau</u>
G√©n√©rer une paire de cl√© curve25519-sha256 (ECDH avec Curve25519 et SHA2) pour une liaison SSH avec le serveur.  

    ssh-keygen -t ed25519 -o -a 100 -f ~/.ssh/lenovo-ed25519

Envoyer les cl√©s publiques sur le serveur KVM   

    ssh-copy-id -i ~/.ssh/lenovo-ed25519.pub leno@192.168.0.215

<u>sur le serveur KVM</u>  
On se connecte  

    ssh root@192.168.0.215

Cr√©er une configuration serveur SSH  `/etc/ssh/sshd_config.d/lenovo.conf`

```conf
PermitRootLogin no 
Port = 55215
PasswordAuthentication no
ChallengeResponseAuthentication yes 
```

Relancer le serveur

    systemctl restart sshd

Test connexion

    ssh -p 55215 -i ~/.ssh/lenovo-ed25519 leno@192.168.0.215

### Mises √† jour proxmox

On se connecte en utilisateur leno sur proxmox

    ssh -p 55215 -i ~/.ssh/lenovo-ed25519 leno@192.168.0.215

Acc√©s root par commande `su`  

On d√©sactive les d√©p√¥ts entreprise dans les fichiers `/etc/apt/sources.list.d/pve-enterprise.list` et `/etc/apt/sources.list.d/ceph.list`

```
# /etc/apt/sources.list.d/pve-enterprise.list
#deb https://enterprise.proxmox.com/debian/pve bullseye pve-enterprise
# /etc/apt/sources.list.d/ceph.list 
# deb https://enterprise.proxmox.com/debian/ceph-quincy bookworm enterprise
```

Lancer les mises √† jour : `apt update && apt upgrade`  
Installer sudo : `apt install sudo`  

Le fichier `/etc/sudoers`

```shell
#
# This file MUST be edited with the 'visudo' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# This fixes CVE-2005-4890 and possibly breaks some versions of kdesu
# (#1011624, https://bugs.kde.org/show_bug.cgi?id=452532)
Defaults	use_pty

# This preserves proxy settings from user environments of root
# equivalent users (group sudo)
#Defaults:%sudo env_keep += "http_proxy https_proxy ftp_proxy all_proxy no_proxy"

# This allows running arbitrary commands, but so does ALL, and it means
# different sudoers have their choice of editor respected.
#Defaults:%sudo env_keep += "EDITOR"

# Completely harmless preservation of a user preference.
#Defaults:%sudo env_keep += "GREP_COLOR"

# While you shouldn't normally run git as root, you need to with etckeeper
#Defaults:%sudo env_keep += "GIT_AUTHOR_* GIT_COMMITTER_*"

# Per-user preferences; root won't have sensible values for them.
#Defaults:%sudo env_keep += "EMAIL DEBEMAIL DEBFULLNAME"

# "sudo scp" or "sudo rsync" should be able to use your SSH agent.
#Defaults:%sudo env_keep += "SSH_AGENT_PID SSH_AUTH_SOCK"

# Ditto for GPG agent
#Defaults:%sudo env_keep += "GPG_AGENT_INFO"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Allow members of group sudo to execute any command
#%sudo	ALL=(ALL:ALL) ALL

## Read drop-in files from /etc/sudoers.d
@includedir /etc/sudoers.d
```

Donner les droits root √† leno : `echo "leno     ALL=(ALL) NOPASSWD: ALL" >> /etc/sudoers.d/leno`  

### Hostname

Les fichiers

```
root@proxleno:/home/leno# cat /etc/hosts
127.0.0.1 localhost.localdomain localhost
192.168.0.215 pve.home.arpa pve

# The following lines are desirable for IPv6 capable hosts

::1     ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
ff02::3 ip6-allhosts

root@pve:~# cat /etc/hostname
pve.home.arpa

root@pve:/home/leno# hostnamectl
 Static hostname: pve.home.arpa
       Icon name: computer-desktop
         Chassis: desktop üñ•Ô∏è
      Machine ID: a154e9db532d4b4db188a0bd11563557
         Boot ID: 9195561d41a14df9b4494c4d8223a47a
Operating System: Debian GNU/Linux 12 (bookworm)  
          Kernel: Linux 6.8.12-9-pve
    Architecture: x86-64
 Hardware Vendor: Lenovo
  Hardware Model: ThinkCentre M700
Firmware Version: FWKTBCA
```

### Motd

*On se connecte en utilisateur leno sur proxmox via SSH*

Les outils

```shell
sudo apt install jq figlet
```

Effacer et cr√©er motd

    sudo rm /etc/motd && sudo nano /etc/motd

```
 _ __  _ _  ___ __ __ _ __   ___ __ __                              
| '_ \| '_|/ _ \\ \ /| '  \ / _ \\ \ /                              
| .__/|_|  \___//_\_\|_|_|_|\___//_\_\                              
|_|                 _                                               
 _ __ __ __ ___    | |_   ___  _ __   ___     __ _  _ _  _ __  __ _ 
| '_ \\ V // -_) _ | ' \ / _ \| '  \ / -_) _ / _` || '_|| '_ \/ _` |
| .__/ \_/ \___|(_)|_||_|\___/|_|_|_|\___|(_)\__,_||_|  | .__/\__,_|
|_|                                                     |_|         
 _  ___  ___     _   __  ___     __     ___  _  ___                 
/ |/ _ \|_  )   / | / / ( _ )   /  \   |_  )/ || __|                
| |\_, / / /  _ | |/ _ \/ _ \ _| () |_  / / | ||__ \                
|_| /_/ /___|(_)|_|\___/\___/(_)\__/(_)/___||_||___/                
```

Script ssh_rc_bash

>ATTENTION!!! Les scripts sur connexion peuvent poser des probl√®mes pour des appels externes autres que ssh

Installer le bash  

```bash
wget https://static.rnmkcy.eu/files/ssh_rc_bash
chmod +x ssh_rc_bash # rendre le bash ex√©cutable
./ssh_rc_bash        # ex√©cution
```

![](proxmox0004.png)

### NFS Client

Configuration du client NFS sur Proxmox

    sudo apt install nfs-common

Point de montage et lien

```shell
sudo mkdir -p /mnt/sharenfs
sudo ln -s /mnt/sharenfs $HOME/sharenfs
```

Ajouter les points de montage du serveur nfs: `sudo nano /etc/fstab`
	
```
192.168.0.205:/sharenfs	/mnt/sharenfs nfs4 nofail,x-systemd.automount,x-systemd.requires=network-online.target,x-systemd.device-timeout=10s,rsize=8192,wsize=8192 0 0
```

Rechargement et montage

```shell
sudo systemctl daemon-reload && sudo mount -a
```

### D√©sactiver le message "no valid subscription"

D√©sactiver "no valid subscription" sur Proxmox

1. Se connecter sur le serveur proxmox via SSH
2. Passer en mode su  
3. Saisissez la commande suivante pour d√©sactiver le message d'abonnement et appuyez sur Entr√©e

```shell
sed -Ezi.bak "s/(Ext.Msg.show\(\{\s+title: gettext\('No valid sub)/void\(\{ \/\/\1/g" /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js && systemctl restart pveproxy.service
```

### Clavier et langue

Langue, fichier `/etc/pve/datacenter.cfg`

```shell
keyboard: fr
language: fr
```

### pve.home.arpa

**Ajout autorit√© certification home.arpa**

```shell
cp /mnt/sharenfs/cwwk/homearpaCA.crt /usr/local/share/ca-certificates/
update-ca-certificates
```

**Nginx web**

Installation

```shell
apt update && apt install nginx
```
**Domaine pve.home.arpa**  
Certificats **pve.home.arpa.crt** **pve.home.arpa.key** dans `/etc/ssl/private/`

Cr√©er un fichier `/etc/nginx/conf.d/pve.home.arpa.conf`

```shell
upstream proxmox {
    server "pve.home.arpa";
}
 
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    rewrite ^(.*) https://$host$1 permanent;
}
 
server {
    listen 443 ssl;
    listen [::]:443 ssl;
    server_name _;
    ssl_certificate      /etc/ssl/private/pve.home.arpa.crt;
    ssl_certificate_key  /etc/ssl/private/pve.home.arpa.key;
    proxy_redirect off;
    location / {
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_pass https://127.0.0.1:8006;
        proxy_buffering off;
        client_max_body_size 0;
        proxy_connect_timeout  3600s;
        proxy_read_timeout  3600s;
        proxy_send_timeout  3600s;
        send_timeout  3600s;
    }
}
```

V√©rifier

```shell
nginx -t
```

Red√©marrer le serveur

```shell
systemctl restart nginx
```

Acc√®s <https://pve.home.arpa>

### Authentification 2FA

Ajout authentification √† 2 facteurs  
![](proxmox0050.png) 

![](proxmox0051.png){:width="400" .normal}  
Renseigner Description et mot de passe et scanner le code avec application mobile AEGIS   

![](proxmox0052.png){:width="200" .normal}  ![](proxmox0053.png){:width="200" .normal}  

![](proxmox0051.png){:width="400" .normal}  
Saisir le code **329627** dans **V√©rifier le code** puis cliquer sur **Ajouter**

![](proxmox0054.png)  
Authentification TOTP ajouter √† l'utilisateur leno

### Connexion Web

Ensuite, vous pouvez acc√©der √† votre serveur Proxmox √† partir d'un navigateur et de son adresse IP : 
<https://192.168.0.215:8006> ou <https://pve.home.arpa>

L'acc√®s est possible en ligne de commande directement sur le serveur, mais je vous propose de basculer sur votre poste de travail pour acc√©der √† votre serveur Proxmox et poursuivre ce tutoriel. Authentifiez-vous sur l'interface Web de Proxmox avec le compte "root" et le mot de passe d√©fini lors de l'installation ou le nouvel utilisateur **leno**.  
![](proxmox0001.png){: .normal}  
Pr√©cisions concernant l'option "Realm" du formulaire d'authentification :

*    PAM est le module d'authentification enfichable utilis√© dans les syst√®mes d'exploitation Linux/UNIX/BSD pour stocker les informations de l'utilisateur local. Il est stock√© au niveau du syst√®me et d√©l√®gue l'autorisation de se connecter √† une machine. C'est le module par d√©faut sous Linux.
*    PVE est une base de donn√©es stock√©e dans Proxmox qui stocke des informations sur les utilisateurs pouvant se connecter √† l'interface Web de Proxmox. Elle n'accorde pas d'autorisation pour des choses comme la connexion SSH ou Shell au syst√®me d'exploitation sous-jacent, au lieu de cela, il d√©l√®gue uniquement l'autorisation de se connecter aux interfaces Proxmox, comme la WebGUI ou l'API.

![](proxmox0001a.png)  

### Compte admin √† Proxmox

Cr√©er le groupe **Administrateur** et modifier l'utilisateur leno  
![](proxmox0055.png){: .normal} 

Puis dans l‚Äôonglet Permissions, indiquons qu‚Äôil s‚Äôagit d‚Äôun administrateur par Ajouter / Permissions de l‚ÄôUtilisateur avec un r√¥le Administrator et en s√©lectionnant votre utilisateur pr√©c√©demment cr√©√©

## Proxmox Pare-feu

* [S√©curisation basique de son Proxmox](https://doc.ataxya.net/books/proxmox-ve/page/securisation-basique-de-son-proxmox)

### Pare-feu int√©gr√©

Le pare-feu int√©gr√© de Proxmox

* Web interface: 8006 (TCP, HTTP/1.1 over TLS)
* VNC Web console: 5900-5999 (TCP, WebSocket)
* SPICE proxy: 3128 (TCP)
* sshd (used for cluster actions): 22 (TCP)
* rpcbind: 111 (UDP)
* sendmail: 25 (TCP, outgoing)
* corosync cluster traffic: 5405-5412 UDP
* live migration (VM memory and local-disk data): 60000-60050 (TCP)

Trois niveaux de pare-feu

1. Pare-feu du "Centre de donn√©es" (Datacenter)
2. Pare-feu des n≈ìuds (nodes)
3. Pare-feu des machines virtuelles et conteneurs

### R√®gles √† cr√©er

Cr√©er des r√®gles pour le "Centre de donn√©es" (Datacenter) avant d‚Äôactiver le pare-feu  
Pour ajouter des r√®gles : "Centre de donn√©es" (Datacenter) &rarr; Pare-feu &rarr; [Ajouter]   
![](pve-firewall01.png){: .normal}


Attention ! il y a des r√®gles √† cr√©er avant l‚Äôactivation du pare-feu  

![](pve-firewall02.png){:width="400" .normal}  
Pour autoriser le port 8006 en TCP pour le portail WEB d‚Äôadministration de Proxmox.  
Ne pas oublier de cocher activer

![](pve-firewall03.png){:width="400" .normal}  
Pour autoriser le port 55215 (par d√©faut 22) en TCP pour l‚Äôacc√®s en SSH

![](pve-firewall04.png){:width="400" .normal}  
Les r√®gles.

### Activation du pare-feu "Centre de donn√©es"

Lorsque toutes vos r√®gles sont activ√©es, vous pouvez maintenant activer le pare-feu en vous rendant
dans : "Centre de donn√©es" (Datacenter) &rarr; Parefeu   
![](pve-firewall05.png){: .normal}  

![](pve-firewall06.png){:width="400" .normal}   
Par d√©faut, tout ce qui entre est rejet√©, tout ce qui sort est accept√©.

### Cr√©ation groupe de s√©curit√©

Les groupes de s√©curit√© permettent de regrouper plusieurs r√®gles de pare-feu en une seule r√®gle.  
Ils sont cr√©√©s uniquement dans la zone "Centre de donn√©es" (Datacenter)
Exemple "ServeurWEB" avec les ports (55215, 80, 443, etc.).  
"Centre de donn√©es" (Datacenter) &rarr; Parefeu &rarr; Groupe de s√©curit√©  
Cliquez sur Cr√©er, donnez un nom.  
![](pve-firewall07.png){:width="250" .normal}   
Vous pouvez s√©lectionner ce groupe et cliquez sur [Ajouter] dans la partie droite pour commencer √†
ajouter toutes les r√®gles de pare-feu.  
![](pve-firewall08.png){:width="500" .normal}   
Ls r√®gles (in, ACCEPT, tcp, Port destination) pour le port 80 http, port 443 HTTPS et SSH (port 55215) 

Le r√©sultat.  
![](pve-firewall09.png){: .normal}   

### Activation groupe de s√©curit√© pour une machine

Pour les r√®gles. Rendez-vous dans la partie Parefeu de votre machine virtuelle et cliquez sur [Ins√©rer: Groupe de
s√©curit√©].  
![](pve-firewall10.png){: .normal}   
Choisissez le groupe de s√©curit√© qui vous convient et cochez Activer.  

![](pve-firewall11.png){: .normal}   

### Activer le pare-feu d‚Äôune machine
S√©lectionnez la machine &rarr; Parefeu &rarr; Options &rarr; S√©lectionnez Parefeu &rarr; [√âditer]  
Cochez Parefeu &rarr; [OK]  
![](pve-firewall12.png){: .normal}   

![](pve-firewall13.png){: .normal}   

### Alias "Centre de donn√©es" (Datacenter)

Alias va permettre de nommer les IP ou les plages d‚ÄôIP √† utiliser dans le pare-feu.
"Centre de donn√©es" (Datacenter) &rarr; Pare-feu &rarr; Alias &rarr; [Ajouter]  
![](pve-firewall14.png){:width="250" .normal}  ![](pve-firewall15.png){:width="250" .normal}  
On peut ajouter une plage d‚Äôadresse IP avec le CIDR (par exemple 192.168.1.0/24).

![](pve-firewall16.png){: .normal}   

### IPSet

R√®gles de pare-feu qui correspondent aux adresse IP ou aux sous-r√©seaux IP.  
Exemple : IPSet nomm√© "Admin".  
Peuvent √™tre cr√©es dans les niveaux de pare-feu (Datacenter, VM et conteneurs).  
Permet de cr√©er des listes blanches et des listes noires d‚Äôadresses IP.  
"Centre de donn√©es" (Datacenter) &rarr; Parefeu &rarr; IPSet &rarr; [Cr√©er]  
![](pve-firewall17.png){: .normal}  
Nommez l‚ÄôIPSet &rarr; [OK]

![](pve-firewall18.png){: .normal}  
Cliquez sur l‚ÄôIPSet &rarr; [Ajouter] √† droite.

Au final  
![](pve-firewall19.png){: .normal}  

### R√®gles pour une machine virtuelle ou un conteneur

Exemple pour autoriser le ping (protocole ICMP).  
On s√©lectionne la machine &rarr; Parefeu &rarr; [Ajouter]  
![](pve-firewall20.png){: .normal}  
Saisir les param√®tres, macro Ping, ne pas oublier de cocher Activer.  
Comme source, **adminpset** 

Au final  
![](pve-firewall21.png){: .normal}  


## G√©rer la machine Lenovo Proxmox

### cwwk - Domaine pve.home.arpa

*Proxmox pve.home.arpa*

G√©n√©rer les certicicats du domaine local `pve.home.arpa`

```shell
# Machine cwwk
cd $HOME
./gencert.sh pve.home.arpa
# Copie et d√©placement
sudo cp pve.home.arpa.crt /etc/ssl/private/
sudo cp pve.home.arpa.key /etc/ssl/private/
mv pve.home.arpa.crt $HOME/sharenfs/rnmkcy/cwwk/home/yick/CA/
mv pve.home.arpa.key $HOME/sharenfs/rnmkcy/cwwk/home/yick/CA/
```

Fichier de configuration proxy nginx `/etc/nginx/conf.d/pve.home.arpa.conf`

```
upstream pvex {
    server 192.168.0.215:8006;
}

server {
    # ipv4 listening port/protocol
    listen       443 ssl http2;
    # ipv6 listening port/protocol
    listen           [::]:443 ssl http2;
    server_name  pve.home.arpa;

    ssl_certificate      /etc/ssl/private/pve.home.arpa.crt;
    ssl_certificate_key  /etc/ssl/private/pve.home.arpa.key;

   location / {
    proxy_pass https://pvex;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "Upgrade";
    proxy_buffering off;
   }

}
```

V√©rification et rechargement nginx 

```shell
sudo nginx -t
sudo systemctl reload nginx
```

## Gestion distante d√©marrage et arr√™t

*On veut d√©marrer ou √©teindre, depuis le poste linux PC1, la machine distante Lenovo Proxmox (pve.rnmkcy.eu) via ssh et ‚Äúwake on lan‚Äù*

[D√©marrer ou √©teindre une machine distante sur le r√©seau via ssh et "wake on lan"](/posts/demarrer_eteindre_une_machine_via_ssh_et_wake_on_lan/)

**Poste linux PC1 (archlinux/EndeavourOS)**  
Installer wake on lan

```shell
sudo apt install wakeonlan # Debian/Ubuntu 
yay -S wakeonlan # archlinux
```

Rechercher adresse Mac de la machine Lenovo Proxmox

```shell
ping -c3 pve.home.arpa && arp -n
```

![](wol01.png)

Lenovo Proxmox : `192.168.0.215            ether   00:23:24:c9:06:86`

* [PC1 - Script au d√©marrage](/posts/demarrer_eteindre_une_machine_via_ssh_et_wake_on_lan/#pc1---script-au-d√©marrage)
* [PC1 - Script √† l‚Äôarr√™t](/posts/demarrer_eteindre_une_machine_via_ssh_et_wake_on_lan/#pc1---script-√†-larr√™t)

### Client SPICE

*Le protocole SPICE est utilis√© pour acc√©der graphiquement √† la console de vos machines virtuelles sur Proxmox.*

Il est plus agr√©able d'utilisation que le serveur VNC utilis√© par d√©faut √† travers le navigateur puisqu'il permet une meilleure int√©gration ainsi que le support du copier-coller (ce qui est extr√™mement avantageux).  
[[Proxmox] Spice](https://wiki.neopipe.fr/books/proxmox/page/proxmox-spice)

Ensuite il vous faut un logiciel client SPICE sur votre machine pour pouvoir acc√©der √† la console via le protocole.

Pour cela, je vous recommande d'installer le paquet virt-viewer :

    apt install -y virt-viewer

D√©sormais, une fois sur Proxmox lorsque vous cliquerez sur le bouton Console, un fichier sera t√©l√©charg√© sur votre machine.

Il vous suffira de l'ouvrir avec virt-viewer et le tour est jou√© ! 


### Importer un fichier ISO dans Proxmox

Afin de pouvoir installer les syst√®mes d‚Äôexploitation sur nos diff√©rentes machines virtuelles, nous devons au pr√©alable t√©l√©charger les images syst√®me (ISO) et les importer dans Proxmox.

> Les fichiers ISO sont stock√©s dans le dossier `/var/lib/vz/template/iso/`
{: .prompt-tip }

Pour cela, Proxmox dispose d‚Äôun √©l√©ment assez sympa je trouve, une sorte de banque o√π seront stock√©s toutes vos images. Proc√©dez comme ceci :

S√©lectionnez votre n≈ìud puis le stockage (**local**, dans notre cas).  

Cliquez sur "ISO Images", puis sur le bouton "Upload" et recherchez l‚Äôimage √† importer sur votre disque local.  
![](proxmox0002.png){: .normal}  
![](proxmox0003.png){: .normal}  
R√©p√©ter l‚Äôop√©ration autant de fois que n√©cessaire selon la quantit√© d‚Äôimages ISO √† importer, la seule limite c‚Äôest votre espace de stockage.  
Les fichiers ISO sont stock√©s dans le dossier `/var/lib/vz/template/iso/`

### Comment utiliser le disque EFI dans Proxmox

[How to Use EFI Disk in Proxmox?](https://www.vinchin.com/tech-tips/proxmox-efi-disk.html)

Ajouter EFI Disque via la ligne de commande

```shell
qm ensemble 100 --bios ovmf
qm set 100 --efidisk0 local-lvm:1,format=raw
# Remplacer 100 par votre ID VM, et local-lvm par votre nom de stockage
```

### Affecter un USB h√¥te √† l'invit√©

[Comment activer l‚ÄôUSB Passthrough pour Home Assistant sous Proxmox ?](https://www.domo-blog.fr/comment-activer-usb-passthrough-proxmox-home-assistant-domotique/)

Voie simple: passez l'identifiant du p√©riph√©rique USB √† l'invit√©

Attribuer une cl√© Yubikey connect√©e √† l'h√¥te √† VM 103

    lsusb

```
Bus 001 Device 004: ID 1050:0407 Yubico.com Yubikey 4/5 OTP+U2F+CCID
```

Assignez-le √† la VM en mode su par

```
qm set 103 -usb0 host=1050:0407
```

R√©ponse: `update VM 103: -usb0 host=1050:0407`

Eteindre la VM (en cours d'ex√©cution) et relancer

### Sauvegarder et restaurer des machines virtuelles

[Comment sauvegarder et restaurer des machines virtuelles dans Proxmox](https://fr.linux-console.net/?p=29358)



## Machines virtuelles et conteneurs

### Cr√©ation machine virtuelle

Pour cr√©er une nouvelle machine virtuelle, il faut cliquer sur le bouton "Cr√©er une VM" en haut √† droite de l‚Äôinterface.  
![](proxmox0007.png){: .normal}  
il faut nommer la machine 

Pour un ordonnancement correct, il sera utile de d√©finir une nomenclature de nommage, je vous propose, ceci :

*    VM-[ID de la VM] ‚Äì OS-Nom de la machine
*    CT-[ID du conteneur] ‚Äì OS-Nom de la machine

![](proxmox0008.png){:width="500" .normal}  

Le "Resource Pool" ne sera utilis√© que si vous avez plusieurs emplacements de stockage sur le Proxmox (pour de l‚Äôordonnancement / backup, etc.).

S√©lectionnez √† pr√©sent l‚ÄôISO que vous souhaitez installer sur la machine et le type de syst√®me correspondant. Particularit√© pour une VM freeBSD, on s√©lectionnera ¬´ Other ¬ª.  
![](proxmox0009.png){:width="500" .normal}  
Sachez qu'il est aussi possible d‚Äôutiliser directement le lecteur de CD/DVD physique, voir une cl√© USB directement branch√©e au serveur.   

**Pour les conteneurs**,les templates pr√©configur√©s sont t√©l√©chargeables directement via l‚Äôinterface et il est demand√© si vous souhaitez d√©finir un mot de passe d√®s la cr√©ation.

Sur l‚Äô√©cran suivant, on peut configurer certains aspects du syst√®me, en cochant ¬´ Advanced ¬ª. Ainsi, il sera possible de modifier le type de Firmware (BIOS ou UEFI), le type de disque (IDE, SCSI, SATA) et l‚Äô√©mulation SSD, le d√©marrage automatique, le type de CPU, etc.
![](proxmox0010.png){:width="500" .normal}  

L‚Äô√©tape suivante consiste √† configurer le stockage de la machine virtuelle, avec le choix du disque dur, son type et sa taille.  
![](proxmox0011.png){:width="500" .normal}    

√Ä pr√©sent, il s‚Äôagit de d√©finir les sp√©cifications du CPU, avec √©ventuellement la possibilit√© de modifier les vCPU (processeurs virtuels).  
![](proxmox0012.png){:width="500" .normal}  

Ensuite, nous d√©finissons la quantit√© de m√©moire RAM allou√©e √† cette VM, il est alors possible d‚Äôallouer une quantit√© maximale et minimale (en **mode avanc√©**), permettant de limiter la monopolisation des ressources en fonction de l‚Äôutilisation de la machine.  
![](proxmox0013.png){:width="500" .normal}  

La partie Network est assez simple en soi sur une VM, on s√©lectionne l‚Äôinterface (Bridge) sur laquelle on souhaite avoir la VM et √©ventuellement le tag du VLAN (VLAN Tag).  
![](proxmox0014.png){:width="500" .normal}  

Nous sommes √† la derni√®re √©tape o√π nous avons le droit √† un r√©sum√©. Si cela vous convient, cliquez sur **"Termin√©"** pour cr√©er la machine virtuelle. Cela n'installe pas le syst√®me d'exploitation dans la VM, mais la machine sera pr√™te √† l'installation.  
![](proxmox0015.png){:width="500" .normal}  
Notre VM est alors cr√©√© et nous pouvons √† pr√©sent la retrouver dans notre node (partie de gauche de l'interface).  
![](proxmox0016.png)  

### Ajout EFI

[How to add an EFI disk in Proxmox?](https://www.vinchin.com/tech-tips/proxmox-efi-disk.html)

[OVMF/UEFI Boot Entries](https://pve.proxmox.com/wiki/OVMF/UEFI_Boot_Entries)

https://www.bgocloud.com/knowledgebase/95/making-your-first-virtual-machine-and-container-in-proxmox-ve.html

### D√©marrage VM

Pour pouvoir lancer la VM nouvellement cr√©√©e, il suffit de faire un clic droit sur l‚Äôic√¥ne de la machine dans le menu de gauche et de s√©lectionner "D√©marrer"  
L‚Äôautre option est de la s√©lectionner la VM, comme nous venons de le faire, puis de s√©lectionner **"D√©marrer"** en haut √† droite de l‚Äô√©cran. D‚Äôailleurs, ce menu comporte un bouton **"Plus"** qui permet de d√©truire une machine et son stockage associ√©, c'est-√†-dire le disque virtuel. Ce menu permet aussi de cr√©er un Template (c'est-√†-dire un mod√®le de VM), que l'on pourra cloner √† souhait (plut√¥t pratique).  
![](proxmox0017.png){: .normal}  

Une fois la machine d√©marr√©e, nous avons acc√®s aux m√©triques en s√©lectionnant **"R√©sum√©"** (charge CPU, RAM, espace de stockage, etc.).  
![](proxmox0018.png){: .normal}  

De la m√™me fa√ßon, il est possible de suivre l‚Äô√©tat de votre hyperviseur en s√©lectionnant : **"Centre de donn√©es"** puis **"R√©sum√©"**.  
![](proxmox0019.png){: .normal}  

Pour acc√©der √† la machine virtuelle ou au conteneur, il suffit de double-cliquer sur son ic√¥ne dans le menu de gauche. Cette manipulation ouvre une fen√™tre qui donne un acc√®s √† l‚Äôinterface graphique de la machine virtuelle.  
![](proxmox0020.png)   
Sur la capture d'√©cran ci-dessus, on peut voir une fl√®che sur le c√¥t√© gauche, celle-ci permet d‚Äôavoir acc√®s √† des options suppl√©mentaires de la VM, telles que :

*    Mettre en plein √©cran
*    Activer une combinaison de touche (CTRL+ALT+SUPPR)
*    D√©marrage, arr√™t, rafraichir l‚Äôinterface
*    Etc...

Note : sous Linux, si vous utiliser CTRL+W pour une recherche avec l'√©diteur "nano", la fen√™tre va se fermer sans pour autant √©teindre la VM, il faut alors s√©lectionner [A], puis [CTRL], puis apr√®s votre touche [W] afin de permettre la recherche. Une fois le mot trouv√©, d√©sactivez la fonctionnalit√©.
{: .prompt-info }

![](proxmox0020a.png)   

Il ne reste plus qu'√† proc√©der √† l'installation du syst√®me d'exploitation, que ce soit du Linux ou du Windows !

### Erreurs

*VM quit/powerdown failed - got timeout*

**Erreur de d√©lai d'attente**  

L'erreur de d√©lai d'attente se produit lorsque la machine virtuelle est verrouill√©e ou que le processus est toujours en cours d'ex√©cution en arri√®re-plan.

Si la machine virtuelle est verrouill√©e, nous d√©verrouillons la VM et l'arr√™tons. 
Sinon, nous nous connectons au n≈ìud h√¥te.  
Ensuite, nous trouvons le PID du processus de la machine en utilisant la commande.

    ps aux | grep "/usr/bin/kvm -id VMID"
    ps aux | grep "/usr/bin/kvm -id 100" # VMID=100 dans notre exemple

```
root       15847  0.5  0.6 3779756 49520 ?       Sl   09:58   0:10 /usr/bin/kvm -id 100 -name vm-001-debian11-yunotest -no-shutdown -chardev socket,id=qmp.......................
```

Une fois que nous avons trouv√© le PID, nous tuons le processus en utilisant la commande.

    kill -9 15847  # PID=15847 dans notre exemple

**Arr√™t en mode CLI**  
Nous avons rencontr√© de nombreuses instances qui arr√™tent la machine virtuelle √† partir de l'interface web pour effectuer les t√¢ches.

Ainsi, nous arr√™tons la machine virtuelle √† partir du n≈ìud. Pour arr√™ter la VM, il faut d'abord trouver le VMID.

Nous utilisons donc la commande suivante pour arr√™ter la machine virtuelle

    qm stop <VMID>

Ensuite, en rafra√Æchissant l'interface web, nous pouvons voir que la machine virtuelle est arr√™t√©e.

**VM verrouill√©e**  
L'une des raisons les plus courantes pour lesquelles il est impossible d'arr√™ter une machine virtuelle est que celle-ci a √©t√© verrouill√©e. Cela se produit g√©n√©ralement lorsque nous essayons d'arr√™ter une machine virtuelle alors qu'une sauvegarde est en cours.

La machine virtuelle se verrouille alors pour terminer le processus de sauvegarde. Ainsi, nous pouvons attendre que le processus de sauvegarde supprime la VM. Sinon, nous pouvons d√©verrouiller la machine virtuelle et l'arr√™ter.

Pour d√©verrouiller la VM, nous nous connectons au n≈ìud h√¥te.

Puis nous trouvons le VMID de la machine virtuelle en utilisant la commande

    cat /etc/pve/.vmlist

Une fois que nous avons obtenu le VMID, nous d√©verrouillons la VM √† l'aide de la commande

    qm unlock <VMID>

Apr√®s avoir d√©verrouill√© la machine virtuelle, nous pouvons supprimer la machine virtuelle √† partir de l'interface web ou en utilisant le CLI.

## Cr√©ation Conteneur

### Images des conteneurs

Les images de conteneurs, parfois √©galement appel√©es -templates ou -Appliances, sont des archives tar qui contiennent tout pour ex√©cuter un conteneur.

Proxmox VE lui-m√™me fournit une vari√©t√© de mod√®les de base pour [les distributions Linux les plus courantes](https://pve.proxmox.com/wiki/Linux_Container#pct_supported_distributions). Ils peuvent √™tre t√©l√©charg√©s en utilisant l'utilitaire de ligne de commande GUI ou pveam (short for Proxmox VE Appliance Manager). En outre, les mod√®les de conteneur [TurnKey Linux](https://www.turnkeylinux.org/) sont √©galement disponibles √† t√©l√©charger.

La liste des mod√®les disponibles est mise √† jour quotidiennement par l'interm√©diaire de `pve-daily-update`.  
Vous pouvez √©galement d√©clencher une mise √† jour manuellement en ex√©cutant en mode su :

```shell
pveam update
```

Pour voir la liste des images disponibles tourner:

```shell
pveam available
```

Vous pouvez restreindre cette grande liste en sp√©cifiant la section qui vous int√©resse, par exemple les images syst√®me de base  

```shell
pveam available --section system
```

Liste des images syst√®me disponibles

```
system          almalinux-9-default_20240911_amd64.tar.xz
system          alpine-3.19-default_20240207_amd64.tar.xz
system          alpine-3.20-default_20240908_amd64.tar.xz
system          alpine-3.21-default_20241217_amd64.tar.xz
system          archlinux-base_20240911-1_amd64.tar.zst
system          centos-9-stream-default_20240828_amd64.tar.xz
system          debian-11-standard_11.7-1_amd64.tar.zst
system          debian-12-standard_12.7-1_amd64.tar.zst
system          devuan-5.0-standard_5.0_amd64.tar.gz
system          fedora-41-default_20241118_amd64.tar.xz
system          fedora-42-default_20250428_amd64.tar.xz
system          gentoo-current-openrc_20250508_amd64.tar.xz
system          openeuler-24.03-default_20250507_amd64.tar.xz
system          openeuler-25.03-default_20250507_amd64.tar.xz
system          opensuse-15.6-default_20240910_amd64.tar.xz
system          rockylinux-9-default_20240912_amd64.tar.xz
system          ubuntu-20.04-standard_20.04-1_amd64.tar.gz
system          ubuntu-22.04-standard_22.04-1_amd64.tar.zst
system          ubuntu-24.04-standard_24.04-2_amd64.tar.zst
system          ubuntu-24.10-standard_24.10-1_amd64.tar.zst
system          ubuntu-25.04-standard_25.04-1.1_amd64.tar.zst
```

Au niveau graphique  
![](ct003.png){: .normal}  

![](ct004.png){:width="400" .normal}  

![](ct005.png){: .normal}  

### Alpine Linux

![](alpine-linux-logo.png){:width="250"}  

*Alpine Linux est une distribution Linux l√©g√®re et s√©curis√©e, con√ßue pour √™tre utilis√©e dans des environnements exigeants en termes de performance et de s√©curit√©. Elle est bas√©e sur le noyau Linux et utilise le gestionnaire de paquets ‚Äúapk‚Äù pour g√©rer les applications et les biblioth√®ques.*

Alpine Linux est particuli√®rement adapt√©e aux environnements de virtualisation, de conteneurisation et de cloud, gr√¢ce √† sa taille r√©duite et √† sa consommation faible en ressources. Elle est √©galement utilis√©e dans de nombreux autres contextes, tels que les serveurs Web, les routeurs et les appareils embarqu√©s.


*    Taille r√©duite : Alpine Linux est une distribution tr√®s l√©g√®re, avec une image ISO de seulement 5 Mo, ce qui la rend id√©ale pour les environnements o√π l‚Äôespace disque est limit√©.
*    Consommation faible en ressources : Alpine Linux utilise peu de m√©moire et de CPU, ce qui en fait une excellente option pour les environnements de virtualisation et de conteneurisation o√π les ressources sont partag√©es.
*    Temps de d√©marrage rapide : gr√¢ce √† sa taille r√©duite et √† sa consommation faible en ressources, Alpine Linux d√©marre rapidement et est pr√™t √† √™tre utilis√© en quelques secondes.
*    Faible empreinte en termes de s√©curit√© : Alpine Linux est con√ßue pour √™tre s√©curis√©e d√®s le d√©part, avec une base de code r√©duite et des paquets verrouill√©s par d√©faut. Cela r√©duit le risque de vuln√©rabilit√©s et de menaces de s√©curit√©.


Cr√©er un jeu de cl√®s SSH sur le poste PC1

```shell
ssh-keygen -t ed25519 -o -a 100 -f ~/.ssh/ct-alp01
```

La cl√© publique est disponible sous le dossier `~/.ssh/ct-alp01.pub` 

Les r√©glages g√©n√©raux d'un conteneur incluent

* le n≈ìud : le serveur physique sur lequel le conteneur va fonctionner
* ID CT: un num√©ro unique dans cette installation Proxmox VE utilis√©e pour identifier votre conteneur
* Nom d'h√¥te : le nom d'h√¥te du conteneur
* Resource Pool: un groupe logique de conteneurs et de VMs
* Mot de passe : le mot de passe "root" du conteneur
* SSH Public Key: une cl√© publique pour se connecter au compte racine sur SSH

Conteneur non privil√©gi√© : cette option permet de choisir au moment de la cr√©ation si vous voulez cr√©er un conteneur privil√©gi√© ou non privil√©gi√©.

Se connecter √† l‚Äôinterface de gestion de Proxmox VE  
Cr√©er un conteneur  
![](ct001.png){: .normal}  

![](ct002.png){:width="400" .normal}  
renseigner **Nom d'h√¥te**, **Mot de passe** root (root49600), **Charger le fichier de clef SSH** (ct-alp01.pub)

![](ct002a.png){:width="400" .normal}  

![](ct002b.png){:width="400" .normal}  

![](ct002c.png){:width="400" .normal}  

![](ct002d.png){:width="400" .normal}  

![](ct002e.png){:width="400" .normal}  

![](ct002f.png){:width="400" .normal}  

![](ct002g.png){:width="400" .normal}  

![](ct006.png){: .normal} 

V√©rification en mode console  
![](ct007.png){: .normal} 

En mode console

Mise √† jour

```shell
apk -U upgrade
```

Cr√©er un utilisateur

```shell
setup-user
```

Installer openssh

```shell
apk add openssh
```

Activer le service et lancer

```shell
rc-update add sshd
service sshd start
```

Connexion SSH

```shell
ssh -i ~/.ssh/ct-alp01 root@192.168.0.231
```

### Cockpit

*Cockpit est une interface graphique Web pour la gestion des serveurs Linux. Il permet aux utilisateurs d'effectuer des t√¢ches telles que configurer les r√©seaux, g√©rer le stockage et surveiller les performances du syst√®me directement via un navigateur Web. Il s'int√®gre aux outils syst√®me existants, le rendant adapt√© √† la fois aux d√©butants et aux administrateurs exp√©riment√©s.*

<https://community-scripts.github.io/ProxmoxVE/scripts?id=cockpit>  
Pour cr√©er un nouveau Proxmox VE Cockpit LXC, lancez la commande ci-dessous dans Proxmox VE Shell.

```shell
bash -c "$(curl -fsSL https://raw.githubusercontent.com/community-scripts/ProxmoxVE/main/ct/cockpit.sh)"
```

Fin installation

![](cockpit-lxc.png)  

![](cockpit-lxc01.png)  


Location fichier de configuration : `/etc/cockpit/cockpit.conf`

